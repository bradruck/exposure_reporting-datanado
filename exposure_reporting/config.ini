[project]
name = Exposure_Reporting
data_directory = /tmp

[jira]
url = https://jira.oracledatacloud.com
#username = svc.jira.autobot
username = svc.jira.autover
reporter = james.mencel
troubleshooter = james.mencel

[jql]
active = project in (CAM) AND issuetype = 'Data Enhancement' AND status in ('In Progress') AND product = 'Exposure File' AND 'End Date' <= '{today_minus_two}' AND (labels in ('OM.Processing')) ORDER BY due DESC, priority DESC
jql = project in (CAM) AND issuetype = 'Data Enhancement' AND status in ('In Progress') AND product = 'Exposure File' AND 'End Date' <= '{today_minus_two}' AND (labels is empty or labels not in ('OM.Processing', 'OM.MaidTrigger')) ORDER BY due DESC, priority DESC

[logfile]
#path = /Volumes/dataservices_customerinput/Internal/Exposure_Reporting/Onramp/logs
path = /net/zfs1/export/dataservices_customerinput/Internal/Exposure_Reporting/Onramp/logs
purge_days = 90
min_size = 500

[Datanado]
api_call = http://datanado-job-service.valkyrie.net/api/v1/jobs/launch

[qubole]
#token = 
#token = 
#cluster = Hadoop2

[aws]
bucket = dlx-prod-audience-operations-pii
input_prefix = FlatFileOutput/{audience_file}/{input_folder}/
output_prefix = CustomInitiatives/Exposure_Reporting/Outbox/{report_type}

[s3]
s3_bucket = dlx-prod-analytics
s3_output_prefix = analytics-platform/gold/query/exposure_reporting

[zfs]
#path = /net/zfs1/export/Operations/Exposure_Reporting/Onramp/{issuekey}
#path = /net/zfs1/export/dataservices_customerinput/Internal/Exposure_Reporting/Onramp/{issuekey}
volume = /net/zfs1/export
path= /net/zfs1/export/dataservices_customerinput/Internal/Exposure_Reporting/Onramp/{issuekey}

[qcb]
#url = http://prd-qcbrains-app/v1/event
#project = de_exposure_reporting
#listener = report_gen

[email]
from = odc-dataappend_us@oracle.com
cc = odc-dataappend_us@oracle.com
filename = email.eml
